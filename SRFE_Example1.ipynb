{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schaeffer and Tran 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T16:43:06.297519Z",
     "start_time": "2020-06-18T16:43:06.292644Z"
    }
   },
   "source": [
    "## 1. Import Packages and Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T21:05:20.963077Z",
     "start_time": "2021-01-13T21:05:19.849683Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import spgl1\n",
    "from spgl1 import spgl1, spg_lasso, spg_bp, spg_bpdn, spg_mmv\n",
    "\n",
    "#==============================================================\n",
    "# Activation Function\n",
    "def msin(x):\n",
    "    return np.sin(x)\n",
    "\n",
    "\n",
    "#==============================================================\n",
    "# Target Functions\n",
    "def fn1(x):\n",
    "    s = 0\n",
    "    for i in range(len(x)-1):\n",
    "        s += np.exp(-x[i]**2)/(1+x[i+1]**2)\n",
    "    \n",
    "    return s/len(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1 ( See Figure 1, log of training size = 2.4, q = 2, log of error of SRF ~ -1.6) \n",
    "ED = 250 # training set size (number of measurements m in the paper)\n",
    "n = ED + 5000 # total dataset size (training + validation)\n",
    "d = 10 # ambient dimension \n",
    "q = 2 # dimension of low order features\n",
    "N = 5000 # number of features\n",
    "omega_weight = 1 # scale for the random weights\n",
    "sigma_spgl1 = 1e-2 #s igma_spgl1 = eta* sqrt(m), stability parameter for the B.P. problem\n",
    "mactivation = msin\n",
    "Testing_Func = fn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T21:06:06.899957Z",
     "start_time": "2021-01-13T21:05:20.972962Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Linesearch failed with error 1. Damping max BB scaling to 10000.0\n",
      "Linesearch failed with error 1. Damping max BB scaling to 1000.0\n",
      "Linesearch failed with error 1. Damping max BB scaling to 100.0\n",
      "Linesearch failed with error 1. Damping max BB scaling to 10.0\n",
      "Linesearch failed with error 1. Damping max BB scaling to 1.0\n",
      "Linesearch failed with error 1. Damping max BB scaling to 0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of Training Error (percentage):  0.4152063025120786\n",
      "Average of Testing Error (percentage):  2.3514007459572985\n",
      "Log of Training Size vs Log of Testing Error:  [2.3979400086720375, array([-1.62867335])]\n"
     ]
    }
   ],
   "source": [
    " # basis pursuit denoising: \\|y - Ac \\|_2 <= sigma_spgl1 \n",
    "iterMax_spgl1 = 5000 # maximum number of iterations for BP\n",
    "Runs = 1 # number of random trials\n",
    "error_train_vec_srf = np.zeros(Runs)\n",
    "error_test_vec_srf = np.zeros(Runs)\n",
    "\n",
    "tol_dict = 1e-10\n",
    "sparsity_percentage_vec = np.zeros(Runs)\n",
    "for i in range(Runs):\n",
    "    # Create input-output data\n",
    "    data_input = 2*np.random.rand(n,d)-1\n",
    "    data_output = np.zeros(n)\n",
    "    for j in range(n):\n",
    "        data_output[j] = Testing_Func(data_input[j,:])\n",
    "    \n",
    "\n",
    "    # Create dictionary matrix\n",
    "    \n",
    "    idx = 0\n",
    "    A = np.zeros((n,N))\n",
    "\n",
    "    tmp = 1/np.sqrt(ED)*np.ones(data_input.shape[0])\n",
    "    A[:,0] = tmp\n",
    "\n",
    "    listind =[]\n",
    "    for idx in range(1,N):\n",
    "        w = omega_weight*np.random.randn(q)\n",
    "        p = np.pi*2*np.random.rand(1)\n",
    "\n",
    "        xind = np.random.choice(d,q,replace = False)\n",
    "\n",
    "\n",
    "        tmp = mactivation(np.dot(data_input[:,xind],w) + p)\n",
    "        \n",
    "        scale = np.sqrt(np.dot(tmp[:ED],tmp[:ED])) \n",
    "\n",
    "        if scale>(np.sqrt(n)*tol_dict):\n",
    "            tmp /=scale\n",
    "            A[:,idx] = tmp\n",
    "            \n",
    "    # Create train and test\n",
    "   \n",
    "\n",
    "    A_train = A[:ED,:]\n",
    "    A_test = A[ED:,:]\n",
    "    y_train = data_output[:ED]\n",
    "    y_test = data_output[ED:]\n",
    "    c,resid,grad,info = spg_bpdn(A_train, y_train, sigma = sigma_spgl1, iter_lim= iterMax_spgl1, verbosity=0)\n",
    "    \n",
    "\n",
    "    \n",
    "    y_train_model = np.dot(A_train, c) \n",
    " \n",
    "    error_train = np.linalg.norm(data_output[:ED] - y_train_model)/np.linalg.norm(data_output[:ED])\n",
    "    \n",
    "  \n",
    "    y_test_model= np.dot(A_test, c)\n",
    "    error_test = np.linalg.norm(y_test - y_test_model)/np.linalg.norm(y_test)\n",
    "    error_train_vec_srf[i] = error_train\n",
    "    error_test_vec_srf[i] = error_test\n",
    "\n",
    "print(\"Average of Training Error (percentage): \", np.mean(error_train_vec_srf)*100)\n",
    "print(\"Average of Testing Error (percentage): \", np.mean(error_test_vec_srf)*100)\n",
    "print(\"Log of Training Size vs Log of Testing Error: \", [np.log10(ED), np.log10(error_test_vec_srf)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T21:06:07.072881Z",
     "start_time": "2021-01-13T21:06:06.929843Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T20:41:25.674523Z",
     "start_time": "2021-01-13T20:39:33.194212Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
